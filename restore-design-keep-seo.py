#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åªæ¢å¤bodyå†…å®¹ï¼ˆå¯¼èˆªæ ã€bannerã€é¡µé¢è®¾è®¡ï¼‰ï¼Œä¿ç•™å½“å‰çš„SEOæ ‡ç­¾
"""

import re
from pathlib import Path

def extract_section(html_content, tag_name):
    """æå–æŒ‡å®šæ ‡ç­¾çš„å†…å®¹"""
    # åŒ¹é…å¼€å§‹å’Œç»“æŸæ ‡ç­¾ï¼ˆåŒ…æ‹¬å±æ€§ï¼‰
    pattern = rf'<{tag_name}[^>]*>(.*?)</{tag_name}>'
    match = re.search(pattern, html_content, re.DOTALL | re.IGNORECASE)
    if match:
        return match.group(0)  # è¿”å›å®Œæ•´çš„æ ‡ç­¾åŠå†…å®¹
    return None

def main():
    """ä¸»å‡½æ•°"""
    print('='*60)
    print('ğŸ”„ åªæ¢å¤è®¾è®¡å†…å®¹ï¼Œä¿ç•™å½“å‰SEOæ ‡ç­¾')
    print('='*60)
    print('\nğŸ“‹ ä¿ç•™ï¼ˆä¸å˜ï¼‰:')
    print('  âœ… <title>æ ‡ç­¾')
    print('  âœ… <meta>æ ‡ç­¾ï¼ˆdescription, keywordsç­‰ï¼‰')
    print('  âœ… Open Graphæ ‡ç­¾')
    print('  âœ… Twitter Cardæ ‡ç­¾')
    print('  âœ… Structured Data (JSON-LD)')
    print('')
    print('ğŸ“‹ æ¢å¤ï¼ˆä»backupï¼‰:')
    print('  âœ… å¯¼èˆªæ ï¼ˆnavigation barï¼‰')
    print('  âœ… æ©™è‰²bannerï¼ˆå¦‚æœ‰ï¼‰')
    print('  âœ… é¡µé¢è®¾è®¡å’Œå¸ƒå±€')
    print('  âœ… æ–‡å­—å†…å®¹')
    print('')
    
    # å®šä¹‰è¦å¤„ç†çš„æ–‡ä»¶
    files_to_process = [
        ('index.html', 'backup_latest/index.html', 'zh-TW'),
    ]
    
    success_count = 0
    fail_count = 0
    
    for current_file, backup_file, lang in files_to_process:
        print(f'\nå¤„ç†: {current_file}')
        
        try:
            # 1. è¯»å–å½“å‰æ–‡ä»¶
            if not Path(current_file).exists():
                print(f'  âŒ å½“å‰æ–‡ä»¶ä¸å­˜åœ¨: {current_file}')
                fail_count += 1
                continue
                
            with open(current_file, 'r', encoding='utf-8') as f:
                current_content = f.read()
            
            # 2. è¯»å–å¤‡ä»½æ–‡ä»¶
            if not Path(backup_file).exists():
                print(f'  âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}')
                fail_count += 1
                continue
                
            with open(backup_file, 'r', encoding='utf-8') as f:
                backup_content = f.read()
            
            # 3. æå–å½“å‰çš„headéƒ¨åˆ†ï¼ˆä¿ç•™SEOï¼‰
            print('  - æå–å½“å‰çš„<head>æ ‡ç­¾ï¼ˆä¿ç•™SEOï¼‰...')
            current_head = extract_section(current_content, 'head')
            if not current_head:
                print('  âŒ æ— æ³•æå–å½“å‰çš„<head>æ ‡ç­¾')
                fail_count += 1
                continue
            
            # 4. æå–å¤‡ä»½çš„bodyéƒ¨åˆ†ï¼ˆæ¢å¤è®¾è®¡ï¼‰
            print('  - æå–å¤‡ä»½çš„<body>æ ‡ç­¾ï¼ˆæ¢å¤è®¾è®¡ï¼‰...')
            backup_body = extract_section(backup_content, 'body')
            if not backup_body:
                print('  âŒ æ— æ³•æå–å¤‡ä»½çš„<body>æ ‡ç­¾')
                fail_count += 1
                continue
            
            # 5. æ„å»ºæ–°çš„HTML
            print('  - åˆå¹¶å†…å®¹ï¼ˆä¿ç•™SEO + æ¢å¤è®¾è®¡ï¼‰...')
            new_html = f'''<!DOCTYPE html>
<html lang="{lang}">
{current_head}
{backup_body}
</html>'''
            
            # 6. å†™å›æ–‡ä»¶
            with open(current_file, 'w', encoding='utf-8') as f:
                f.write(new_html)
            
            print(f'  âœ… å®Œæˆï¼')
            print(f'     - SEOæ ‡ç­¾ï¼šä¿æŒä¸å˜ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰')
            print(f'     - é¡µé¢è®¾è®¡ï¼šå·²æ¢å¤ï¼ˆå¤‡ä»½ç‰ˆæœ¬ï¼‰')
            
            success_count += 1
            
        except Exception as e:
            print(f'  âŒ é”™è¯¯: {e}')
            fail_count += 1
    
    print('\n' + '='*60)
    print(f'âœ… å¤„ç†å®Œæˆ: {success_count}ä¸ªæ–‡ä»¶æˆåŠŸ, {fail_count}ä¸ªå¤±è´¥')
    print('='*60)
    
    if success_count > 0:
        print('\nâœ¨ æ¢å¤ç»“æœ:')
        print('  âœ… å¯¼èˆªæ å·²æ¢å¤')
        print('  âœ… é¡µé¢è®¾è®¡å·²æ¢å¤')
        print('  âœ… SEOæ ‡ç­¾ï¼ˆtitleã€metaç­‰ï¼‰ä¿æŒä¸å˜')

if __name__ == '__main__':
    main()

