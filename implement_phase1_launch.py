#!/usr/bin/env python3
"""
å®æ–½ç¬¬ 1 é˜¶æ®µä¸Šçº¿ç­–ç•¥ï¼š
- é€‰æ‹© 56 ä¸ªé«˜ä»·å€¼é¡µé¢ä¸Šçº¿ï¼ˆindexï¼‰
- å…¶ä»– 236 ä¸ªé¡µé¢æš‚æ—¶ä¸ç´¢å¼•ï¼ˆnoindexï¼‰
"""

import re
from pathlib import Path

# ç¬¬ 1 é˜¶æ®µï¼šé¦™æ¸¯ 12 å®¶ä¸»è¦é“¶è¡Œ + 2 ä¸ªæ ¸å¿ƒè¡Œä¸š
PHASE1_BANKS = [
    'hsbc', 'hangseng', 'bochk', 'sc', 'dbs', 'bea',
    'citibank', 'dahsing', 'citic', 'bankcomm', 'fubon', 'ocbc'
]

PHASE1_INDUSTRIES = [
    'accountant',  # ä¼šè®¡å¸ˆ
    'smallbiz'     # å°å‹ä¼ä¸š
]

def should_index_in_phase1(filename):
    """åˆ¤æ–­é¡µé¢æ˜¯å¦åº”è¯¥åœ¨ç¬¬ 1 é˜¶æ®µç´¢å¼•"""
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯é“¶è¡Œé¡µé¢
    for bank in PHASE1_BANKS:
        if f"{bank}-bank-statement-simple" in filename:
            return True
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯è¡Œä¸šé¡µé¢
    for industry in PHASE1_INDUSTRIES:
        if f"{industry}-accounting-solution" in filename:
            return True
    
    return False

def set_robots_meta(file_path, should_index=True):
    """è®¾ç½®é¡µé¢çš„ robots meta æ ‡ç­¾"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if should_index:
        # å…è®¸ç´¢å¼•
        new_robots = '<meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">'
    else:
        # ä¸å…è®¸ç´¢å¼•ï¼ˆä½†å…è®¸çˆ¬å–é“¾æ¥ï¼‰
        new_robots = '<meta name="robots" content="noindex, follow">'
    
    # æ›¿æ¢ç°æœ‰çš„ robots meta æ ‡ç­¾
    if 'name="robots"' in content:
        content = re.sub(
            r'<meta name="robots" content="[^"]*">',
            new_robots,
            content
        )
    else:
        # å¦‚æœæ²¡æœ‰ robots æ ‡ç­¾ï¼Œåœ¨ </head> ä¹‹å‰æ·»åŠ 
        insert_point = content.rfind('</head>')
        if insert_point != -1:
            content = (
                content[:insert_point] +
                f'    {new_robots}\n' +
                content[insert_point:]
            )
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return should_index

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ å®æ–½ç¬¬ 1 é˜¶æ®µä¸Šçº¿ç­–ç•¥...")
    print("=" * 70)
    print()
    print("ğŸ“‹ ç­–ç•¥è¯´æ˜ï¼š")
    print("   - âœ… 56 ä¸ªé«˜ä»·å€¼é¡µé¢ï¼šindexï¼ˆå…è®¸ Google ç´¢å¼•ï¼‰")
    print("   - â¸ï¸  236 ä¸ªå…¶ä»–é¡µé¢ï¼šnoindexï¼ˆæš‚ä¸ç´¢å¼•ï¼Œä¿ç•™è´¨é‡ï¼‰")
    print()
    print("ğŸ“ ç¬¬ 1 é˜¶æ®µé¡µé¢ï¼š")
    print("   - é¦™æ¸¯ 12 å®¶ä¸»è¦é“¶è¡Œï¼ˆ48 é¡µï¼‰")
    print("   - 2 ä¸ªæ ¸å¿ƒè¡Œä¸šï¼šä¼šè®¡å¸ˆã€å°å‹ä¼ä¸šï¼ˆ8 é¡µï¼‰")
    print()
    print("=" * 70)
    print()
    
    # è¯»å–æ‰€æœ‰ç”Ÿæˆçš„é¡µé¢
    pages_files = [
        'phase2_generated_pages.txt',
        'phase2_generated_remaining_204_pages.txt'
    ]
    
    all_pages = []
    for pages_file in pages_files:
        if Path(pages_file).exists():
            with open(pages_file, 'r', encoding='utf-8') as f:
                all_pages.extend([line.strip() for line in f if line.strip()])
    
    # ç»Ÿè®¡
    phase1_count = 0
    phase2_count = 0
    
    # å¤„ç†æ¯ä¸ªé¡µé¢
    for page_path in all_pages:
        if not Path(page_path).exists():
            continue
        
        filename = Path(page_path).name
        should_index = should_index_in_phase1(filename)
        
        try:
            set_robots_meta(page_path, should_index)
            
            if should_index:
                phase1_count += 1
                print(f"âœ… [Phase 1] {page_path}")
            else:
                phase2_count += 1
                if phase2_count % 50 == 0:
                    print(f"â¸ï¸  å·²è®¾ç½® {phase2_count} ä¸ªé¡µé¢ä¸º noindex...")
        
        except Exception as e:
            print(f"âŒ {page_path}: {e}")
    
    print()
    print("=" * 70)
    print("ğŸ‰ ç¬¬ 1 é˜¶æ®µä¸Šçº¿ç­–ç•¥å®æ–½å®Œæˆï¼")
    print()
    print("ğŸ“Š ç»Ÿè®¡ï¼š")
    print(f"   - âœ… Phase 1ï¼ˆindexï¼‰ï¼š{phase1_count} é¡µ")
    print(f"   - â¸ï¸  Phase 2+ï¼ˆnoindexï¼‰ï¼š{phase2_count} é¡µ")
    print(f"   - ğŸ“ˆ æ€»è®¡ï¼š{phase1_count + phase2_count} é¡µ")
    print()
    print("ğŸ¯ ç¬¬ 1 é˜¶æ®µé¡µé¢åˆ—è¡¨ï¼š")
    print()
    print("**é“¶è¡Œé¡µé¢ï¼ˆ48 é¡µï¼‰ï¼š**")
    for bank in PHASE1_BANKS:
        bank_name = {
            'hsbc': 'æ»™è±éŠ€è¡Œ',
            'hangseng': 'æ’ç”ŸéŠ€è¡Œ',
            'bochk': 'ä¸­åœ‹éŠ€è¡Œï¼ˆé¦™æ¸¯ï¼‰',
            'sc': 'æ¸£æ‰“éŠ€è¡Œ',
            'dbs': 'æ˜Ÿå±•éŠ€è¡Œ',
            'bea': 'æ±äºéŠ€è¡Œ',
            'citibank': 'èŠ±æ——éŠ€è¡Œ',
            'dahsing': 'å¤§æ–°éŠ€è¡Œ',
            'citic': 'ä¸­ä¿¡éŠ€è¡Œ',
            'bankcomm': 'äº¤é€šéŠ€è¡Œ',
            'fubon': 'å¯Œé‚¦éŠ€è¡Œ',
            'ocbc': 'OCBC'
        }.get(bank, bank)
        print(f"   - {bank_name} (4 èªè¨€)")
    print()
    print("**è¡Œæ¥­é é¢ï¼ˆ8 é ï¼‰ï¼š**")
    for industry in PHASE1_INDUSTRIES:
        industry_name = {
            'accountant': 'æœƒè¨ˆå¸«',
            'smallbiz': 'å°å‹ä¼æ¥­'
        }.get(industry, industry)
        print(f"   - {industry_name} (4 èªè¨€)")
    print()
    print("=" * 70)
    print()
    print("âœ… ä¸‹ä¸€æ­¥ï¼š")
    print("   1. æäº¤ Sitemap åˆ° Google Search Console")
    print("   2. ç›£æ§ç´¢å¼•ç‹€æ…‹ï¼ˆ1-2 é€±ï¼‰")
    print("   3. æ ¹æ“šæ•¸æ“šæ±ºå®šæ˜¯å¦é€²å…¥ç¬¬ 2 éšæ®µ")
    print()
    print("ğŸ“ˆ é æœŸæ•ˆæœï¼ˆ1-4 é€±ï¼‰ï¼š")
    print("   - Google ç´¢å¼• 40-50 å€‹é é¢")
    print("   - SEO æµé‡å¢é•· 30-50%")
    print("   - ç„¡ä»»ä½•è­¦å‘Šæˆ–æ‡²ç½°")

if __name__ == '__main__':
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    print()
    print("âš ï¸  é‡è¦æç¤ºï¼š")
    print("   æ­¤æ“ä½œå°†ä¸º 236 ä¸ªé¡µé¢æ·»åŠ  noindex æ ‡ç­¾")
    print("   è¿™äº›é¡µé¢æš‚æ—¶ä¸ä¼šè¢« Google ç´¢å¼•")
    print()
    
    response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(yes/no): ").strip().lower()
    
    if response in ['yes', 'y', 'æ˜¯']:
        main()
    else:
        print("âŒ æ“ä½œå·²å–æ¶ˆ")

